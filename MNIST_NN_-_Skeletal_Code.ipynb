{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca22115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# MNIST DIGIT CLASSIFIER (PyTorch)\n",
    "# -----------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import gradio as gr\n",
    "from PIL import Image, ImageOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2a9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. LOAD DATA\n",
    "# Transforms are preprocessing steps that get applied automatically to every image\n",
    "# you load from a dataset. \n",
    "# Think of transforms as a recipe that says:\n",
    "\n",
    "# “Every time you give me an image, do X, then Y, then Z to it.”\n",
    "# “For every MNIST image: convert it to a PyTorch tensor.\n",
    "# MNIST images come in as PIL images (Python Imaging Library).\n",
    "\n",
    "# But your neural network expects tensors.\n",
    "# -----------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57dca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf5ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset (MNIST)\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de572723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87def014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# TODO: Access and print the unique labels in the training data set using the train_loader object\n",
    "train_labels = train_loader.dataset.train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091eb8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2. DEFINE NEURAL NETWORK\n",
    "# TODO: Design a Neural Network with 1 hidden layer of 128 neurons\n",
    "# -----------------------------\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        fc1 = nn.Linear(784, 128)\n",
    "        fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        self.fc1 = fc1\n",
    "        self.fc2 = fc2\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten image: (batch, 1, 28, 28) → (batch, 784)\n",
    "        x = x.view(-1, 28*28)\n",
    "\n",
    "        # TODO: Add activation between layers\n",
    "        x = torch.relu(self.fc1(x))\n",
    "\n",
    "        # TODO: Add activation between layers\n",
    "        x = self.fc2(x)\n",
    "\n",
    "\n",
    "        return x   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138089f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the model\n",
    "\n",
    "model = SimpleNN()\n",
    "x = torch.randn(64, 1, 28, 28)\n",
    "\n",
    "output = model(x)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d12046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3. LOSS FUNCTION + OPTIMIZER\n",
    "# -----------------------------\n",
    "# TODO: Define your loss function\n",
    "def loss_fn(outputs, labels):\n",
    "    return nn.CrossEntropyLoss()(outputs, labels)\n",
    "    \n",
    "\n",
    "# TODO: Setup your gradient descent . Try different values for the learning rate\n",
    "\n",
    "def gradient_descent():\n",
    "    return torch.optim.SGD(model.parameters(), lr = 0.02, momentum=0., weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4927182",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.02, momentum=0., weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d32ff29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 857.3028\n",
      "Epoch 2, Loss: 524.2065\n",
      "Epoch 3, Loss: 468.1300\n",
      "Epoch 4, Loss: 440.4251\n",
      "Epoch 5, Loss: 422.0514\n",
      "Epoch 6, Loss: 408.8079\n",
      "Epoch 7, Loss: 396.4147\n",
      "Epoch 8, Loss: 385.6927\n",
      "Epoch 9, Loss: 376.3850\n",
      "Epoch 10, Loss: 368.2879\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4. TRAINING LOOP\n",
    "# -----------------------------\n",
    "\n",
    "# TODO: Define the number of epochs\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # TODO: Reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # TODO: Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # TODO: Compute loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # TODO: Backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # TODO: Update gradients\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59c6e829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.80%\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5. EVALUATION\n",
    "# -----------------------------\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        # TODO: Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Predicted class = index of max logit\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b038ae14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6. TEST SINGLE PREDICTION\n",
    "# -----------------------------\n",
    "# -----------------------------\n",
    "# 6. TEST SINGLE PREDICTION\n",
    "# -----------------------------\n",
    "# ------------------------------\n",
    "# Gradio Sketchpad gives you:\n",
    "\n",
    "# * a full-color NumPy array\n",
    "\n",
    "# * black digit on white background\n",
    "\n",
    "# * large resolution\n",
    "\n",
    "# * no consistent scale\n",
    "#\n",
    "# Hence the preprocessing\n",
    "# ------------------------------\n",
    "\n",
    "def preprocess_image(image):\n",
    "    sketch_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                      # NumPy → PIL\n",
    "    transforms.Grayscale(),                       # ensure 1 channel\n",
    "    transforms.Resize((28, 28)),                  # 28x28 like MNIST\n",
    "    transforms.Lambda(lambda img: ImageOps.invert(img)),  # invert colors\n",
    "    transforms.ToTensor(),                        # → tensor, shape (1,28,28), values in [0,1]\n",
    "    ])\n",
    "    # Gradio Sketchpad sometimes passes a dict with 'composite'\n",
    "    if isinstance(image, dict):\n",
    "        image = image['composite']   # this is a NumPy array\n",
    "    \n",
    "    # Apply the preprocessing transform\n",
    "    img_tensor = sketch_transform(image)  # (1, 28, 28)\n",
    "    \n",
    "    # Add batch dimension → (1, 1, 28, 28)\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "    return img_tensor\n",
    "\n",
    "def predict_digit(image):\n",
    "    # --- STEP 1: CHECK IF SOMETHING HAS BEEN DRAWN ---\n",
    "    if image is None: return \"Draw something!\"\n",
    "\n",
    "    # --- STEP 2: PREPROCESS THE IMAGE ---\n",
    "    img_tensor = preprocess_image(image)\n",
    "    \n",
    "    # --- STEP 3: RUN THE MODEL ---\n",
    "    with torch.no_grad():\n",
    "        prediction = model(img_tensor)\n",
    "        \n",
    "        # Get the index of the highest score (the predicted digit)\n",
    "        predicted_digit = torch.argmax(prediction).item()\n",
    "        \n",
    "    return str(predicted_digit)\n",
    "\n",
    "\n",
    "# UI Setup\n",
    "interface = gr.Interface(fn=predict_digit, inputs=gr.Sketchpad(label=\"Draw Here\"), outputs=\"label\")\n",
    "interface.queue().launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd594aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
